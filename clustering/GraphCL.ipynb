{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "import GCL.losses as L\n",
    "import GCL.augmentors as A\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from GCL.eval import get_split, SVMEvaluator\n",
    "from GCL.models import DualBranchContrast\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def make_gin_conv(input_dim, out_dim):\n",
    "    return GINConv(nn.Sequential(nn.Linear(input_dim, out_dim), nn.ReLU(), nn.Linear(out_dim, out_dim)))\n",
    "\n",
    "\n",
    "class GConv(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(GConv, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.layers.append(make_gin_conv(input_dim, hidden_dim))\n",
    "            else:\n",
    "                self.layers.append(make_gin_conv(hidden_dim, hidden_dim))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        project_dim = hidden_dim * num_layers\n",
    "        self.project = torch.nn.Sequential(\n",
    "            nn.Linear(project_dim, project_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(project_dim, project_dim))\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        z = x\n",
    "        zs = []\n",
    "        for conv, bn in zip(self.layers, self.batch_norms):\n",
    "            z = conv(z, edge_index)\n",
    "            z = F.relu(z)\n",
    "            z = bn(z)\n",
    "            zs.append(z)\n",
    "        gs = [global_add_pool(z, batch) for z in zs]\n",
    "        z, g = [torch.cat(x, dim=1) for x in [zs, gs]]\n",
    "        return z, g\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, augmentor):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.augmentor = augmentor\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        aug1, aug2 = self.augmentor\n",
    "        x1, edge_index1, edge_weight1 = aug1(x, edge_index)\n",
    "        x2, edge_index2, edge_weight2 = aug2(x, edge_index)\n",
    "        z, g = self.encoder(x, edge_index, batch)\n",
    "        z1, g1 = self.encoder(x1, edge_index1, batch)\n",
    "        z2, g2 = self.encoder(x2, edge_index2, batch)\n",
    "        return z, g, z1, z2, g1, g2\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(encoder_model, contrast_model, dataloader, optimizer):\n",
    "    encoder_model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "\n",
    "        _, _, _, _, g1, g2 = encoder_model(data.x, data.edge_index, data.batch)\n",
    "        g1, g2 = [encoder_model.encoder.project(g) for g in [g1, g2]]\n",
    "        loss = contrast_model(g1=g1, g2=g2, batch=data.batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def test(encoder_model, dataloader):\n",
    "    encoder_model.eval()\n",
    "    x = []\n",
    "    y = []\n",
    "    for data in dataloader:\n",
    "        data = data.to('cuda')\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "        _, g, _, _, _, _ = encoder_model(data.x, data.edge_index, data.batch)\n",
    "        x.append(g)\n",
    "        y.append(data.y)\n",
    "    x = torch.cat(x, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "\n",
    "    split = get_split(num_samples=x.size()[0], train_ratio=0.8, test_ratio=0.1)\n",
    "    result = SVMEvaluator(linear=True)(x, y, split)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\anaconda3\\envs\\black\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "(T): 100%|██████████| 100/100 [00:05<00:00, 18.56it/s, loss=0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No fits were performed. Was the CV iterator empty? Were there no candidates?",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 24>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     21\u001B[0m         pbar\u001B[38;5;241m.\u001B[39mset_postfix({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m: loss})\n\u001B[0;32m     22\u001B[0m         pbar\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[1;32m---> 24\u001B[0m test_result \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(E): Best test F1Mi=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmicro_f1\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, F1Ma=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmacro_f1\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36mtest\u001B[1;34m(encoder_model, dataloader)\u001B[0m\n\u001B[0;32m     35\u001B[0m y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(y, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     37\u001B[0m split \u001B[38;5;241m=\u001B[39m get_split(num_samples\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m0\u001B[39m], train_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m, test_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m---> 38\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mSVMEvaluator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlinear\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Python\\anaconda3\\envs\\black\\lib\\site-packages\\GCL\\eval\\eval.py:57\u001B[0m, in \u001B[0;36mBaseEvaluator.__call__\u001B[1;34m(self, x, y, split)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m split\n\u001B[1;32m---> 57\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Python\\anaconda3\\envs\\black\\lib\\site-packages\\GCL\\eval\\eval.py:70\u001B[0m, in \u001B[0;36mBaseSKLearnEvaluator.evaluate\u001B[1;34m(self, x, y, split)\u001B[0m\n\u001B[0;32m     68\u001B[0m ps, [x_train, y_train] \u001B[38;5;241m=\u001B[39m get_predefined_split(x_train, x_val, y_train, y_val)\n\u001B[0;32m     69\u001B[0m classifier \u001B[38;5;241m=\u001B[39m GridSearchCV(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluator, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams, cv\u001B[38;5;241m=\u001B[39mps, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 70\u001B[0m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m test_macro \u001B[38;5;241m=\u001B[39m f1_score(y_test, classifier\u001B[38;5;241m.\u001B[39mpredict(x_test), average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     72\u001B[0m test_micro \u001B[38;5;241m=\u001B[39m f1_score(y_test, classifier\u001B[38;5;241m.\u001B[39mpredict(x_test), average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmicro\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\Python\\anaconda3\\envs\\black\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    871\u001B[0m     )\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mD:\\Python\\anaconda3\\envs\\black\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1378\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1379\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python\\anaconda3\\envs\\black\\lib\\site-packages\\sklearn\\model_selection\\_search.py:840\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    822\u001B[0m out \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[0;32m    823\u001B[0m     delayed(_fit_and_score)(\n\u001B[0;32m    824\u001B[0m         clone(base_estimator),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    836\u001B[0m     )\n\u001B[0;32m    837\u001B[0m )\n\u001B[0;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    844\u001B[0m     )\n\u001B[0;32m    845\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    846\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    847\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    848\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    849\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    850\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: No fits were performed. Was the CV iterator empty? Were there no candidates?"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda')\n",
    "path = osp.join(osp.pardir, 'datasets')\n",
    "dataset = Planetoid(path, name='Cora', transform=T.NormalizeFeatures())\n",
    "dataloader = DataLoader(dataset, batch_size=128)\n",
    "input_dim = max(dataset.num_features, 1)\n",
    "\n",
    "aug1 = A.Identity()\n",
    "aug2 = A.RandomChoice([A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                       A.NodeDropping(pn=0.1),\n",
    "                       A.FeatureMasking(pf=0.1),\n",
    "                       A.EdgeRemoving(pe=0.1)], 1)\n",
    "gconv = GConv(input_dim=input_dim, hidden_dim=32, num_layers=2).to(device)\n",
    "encoder_model = Encoder(encoder=gconv, augmentor=(aug1, aug2)).to(device)\n",
    "contrast_model = DualBranchContrast(loss=L.InfoNCE(tau=0.2), mode='G2G').to(device)\n",
    "\n",
    "optimizer = Adam(encoder_model.parameters(), lr=0.01)\n",
    "\n",
    "with tqdm(total=100, desc='(T)') as pbar:\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(encoder_model, contrast_model, dataloader, optimizer)\n",
    "        pbar.set_postfix({'loss': loss})\n",
    "        pbar.update()\n",
    "\n",
    "test_result = test(encoder_model, dataloader)\n",
    "print(f'(E): Best test F1Mi={test_result[\"micro_f1\"]:.4f}, F1Ma={test_result[\"macro_f1\"]:.4f}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
